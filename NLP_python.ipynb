{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification for Sentiment Analysis â€“ Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<FreqDist with 39610 samples and 719237 outcomes>\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import movie_reviews as mr\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "stop = stopwords.words('english')\n",
    "all_words = FreqDist(w.lower() for w in mr.words() if w.lower() not in stop and w.lower() not in string.punctuation)\n",
    "print all_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import string\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import movie_reviews as mr\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.classify import NaiveBayesClassifier as nbc\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stop = stopwords.words('english')\n",
    "documents = [([w for w in mr.words(i) if w.lower() not in stop and w.lower() not in string.punctuation], i.split('/')[0]) for i in mr.fileids()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_features = FreqDist(chain(*[i for i,j in documents]))\n",
    "word_features = word_features.keys()[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numtrain = int(len(documents) * 90 / 100)\n",
    "train_set = [({i:(i in tokens) for i in word_features}, tag) for tokens,tag in documents[:numtrain]]\n",
    "test_set = [({i:(i in tokens) for i in word_features}, tag) for tokens,tag in documents[numtrain:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.31\n",
      "Most Informative Features\n",
      "               uplifting = True              pos : neg    =      5.9 : 1.0\n",
      "               wednesday = True              pos : neg    =      3.7 : 1.0\n",
      "             controversy = True              pos : neg    =      3.4 : 1.0\n",
      "                  shocks = True              pos : neg    =      3.0 : 1.0\n",
      "                  catchy = True              pos : neg    =      2.6 : 1.0\n",
      "           appropriately = True              pos : neg    =      2.5 : 1.0\n",
      "                   askew = True              pos : neg    =      2.3 : 1.0\n",
      "                bringing = True              pos : neg    =      2.1 : 1.0\n",
      "              unsinkable = True              pos : neg    =      2.1 : 1.0\n",
      "                 spiders = True              pos : neg    =      2.1 : 1.0\n",
      "              projection = True              pos : neg    =      2.1 : 1.0\n",
      "                  crotch = True              neg : pos    =      1.9 : 1.0\n",
      "               francesca = True              neg : pos    =      1.9 : 1.0\n",
      "                liaisons = True              neg : pos    =      1.9 : 1.0\n",
      "               inanimate = True              neg : pos    =      1.9 : 1.0\n",
      "               shandling = True              neg : pos    =      1.9 : 1.0\n",
      "                 natured = True              pos : neg    =      1.8 : 1.0\n",
      "                  errors = True              neg : pos    =      1.8 : 1.0\n",
      "                 wiseguy = True              pos : neg    =      1.7 : 1.0\n",
      "              insecurity = True              pos : neg    =      1.7 : 1.0\n",
      "           stereotypical = True              neg : pos    =      1.7 : 1.0\n",
      "                 rickman = True              pos : neg    =      1.6 : 1.0\n",
      "                   china = True              pos : neg    =      1.6 : 1.0\n",
      "                   shows = True              pos : neg    =      1.5 : 1.0\n",
      "               therefore = True              pos : neg    =      1.5 : 1.0\n",
      "               comically = True              pos : neg    =      1.5 : 1.0\n",
      "                  wooden = True              neg : pos    =      1.4 : 1.0\n",
      "             originality = True              neg : pos    =      1.4 : 1.0\n",
      "                   yahoo = True              neg : pos    =      1.3 : 1.0\n",
      "                  spotty = True              neg : pos    =      1.3 : 1.0\n",
      "                   music = True              pos : neg    =      1.3 : 1.0\n",
      "                  ====== = True              pos : neg    =      1.2 : 1.0\n",
      "                   stern = True              pos : neg    =      1.2 : 1.0\n",
      "                 faceted = True              pos : neg    =      1.2 : 1.0\n",
      "                 succumb = True              pos : neg    =      1.2 : 1.0\n",
      "               confronts = True              pos : neg    =      1.2 : 1.0\n",
      "               francesco = True              pos : neg    =      1.2 : 1.0\n",
      "                 rawhide = True              pos : neg    =      1.2 : 1.0\n",
      "                 islamic = True              pos : neg    =      1.2 : 1.0\n",
      "               designing = True              pos : neg    =      1.2 : 1.0\n",
      "                   woody = True              pos : neg    =      1.2 : 1.0\n",
      "                    kids = True              pos : neg    =      1.2 : 1.0\n",
      "                   shows = False             neg : pos    =      1.1 : 1.0\n",
      "                     dna = True              neg : pos    =      1.1 : 1.0\n",
      "                   music = False             neg : pos    =      1.0 : 1.0\n",
      "                 cooking = True              neg : pos    =      1.0 : 1.0\n",
      "                   woods = True              pos : neg    =      1.0 : 1.0\n",
      "                bringing = False             neg : pos    =      1.0 : 1.0\n",
      "                    kids = False             neg : pos    =      1.0 : 1.0\n",
      "           appropriately = False             neg : pos    =      1.0 : 1.0\n",
      "               uplifting = False             neg : pos    =      1.0 : 1.0\n",
      "                 hanging = True              neg : pos    =      1.0 : 1.0\n",
      "               therefore = False             neg : pos    =      1.0 : 1.0\n",
      "           stereotypical = False             pos : neg    =      1.0 : 1.0\n",
      "                  catchy = False             neg : pos    =      1.0 : 1.0\n",
      "             originality = False             pos : neg    =      1.0 : 1.0\n",
      "                   china = False             neg : pos    =      1.0 : 1.0\n",
      "             controversy = False             neg : pos    =      1.0 : 1.0\n",
      "                  wooden = False             pos : neg    =      1.0 : 1.0\n",
      "                   woody = False             neg : pos    =      1.0 : 1.0\n",
      "                 natured = False             neg : pos    =      1.0 : 1.0\n",
      "                  shocks = False             neg : pos    =      1.0 : 1.0\n",
      "                   joely = False             pos : neg    =      1.0 : 1.0\n",
      "                   askew = False             neg : pos    =      1.0 : 1.0\n",
      "                  crotch = False             pos : neg    =      1.0 : 1.0\n",
      "               wednesday = False             neg : pos    =      1.0 : 1.0\n",
      "                   stern = False             neg : pos    =      1.0 : 1.0\n",
      "               comically = False             neg : pos    =      1.0 : 1.0\n",
      "                 scraped = False             neg : pos    =      1.0 : 1.0\n",
      "                  mystic = False             neg : pos    =      1.0 : 1.0\n",
      "               confronts = False             neg : pos    =      1.0 : 1.0\n",
      "                  errors = False             pos : neg    =      1.0 : 1.0\n",
      "                 rickman = False             neg : pos    =      1.0 : 1.0\n",
      "              insecurity = False             neg : pos    =      1.0 : 1.0\n",
      "                 wiseguy = False             neg : pos    =      1.0 : 1.0\n",
      "              miniatures = False             pos : neg    =      1.0 : 1.0\n",
      "               circuitry = False             pos : neg    =      1.0 : 1.0\n",
      "               shandling = False             pos : neg    =      1.0 : 1.0\n",
      "               francesca = False             pos : neg    =      1.0 : 1.0\n",
      "               inanimate = False             pos : neg    =      1.0 : 1.0\n",
      "                liaisons = False             pos : neg    =      1.0 : 1.0\n",
      "              projection = False             neg : pos    =      1.0 : 1.0\n",
      "              unsinkable = False             neg : pos    =      1.0 : 1.0\n",
      "                 spiders = False             neg : pos    =      1.0 : 1.0\n",
      "                   elgar = False             neg : pos    =      1.0 : 1.0\n",
      "                   ching = False             neg : pos    =      1.0 : 1.0\n",
      "                  gorman = False             neg : pos    =      1.0 : 1.0\n",
      "               mesmerize = False             neg : pos    =      1.0 : 1.0\n",
      "                   scold = False             neg : pos    =      1.0 : 1.0\n",
      "                 emerich = False             neg : pos    =      1.0 : 1.0\n",
      "                grueling = False             neg : pos    =      1.0 : 1.0\n",
      "                     taj = False             neg : pos    =      1.0 : 1.0\n",
      "                capoeira = False             neg : pos    =      1.0 : 1.0\n",
      "                sidebars = False             neg : pos    =      1.0 : 1.0\n",
      "                mutinies = False             neg : pos    =      1.0 : 1.0\n",
      "                  fonzie = False             neg : pos    =      1.0 : 1.0\n",
      "               outraging = False             neg : pos    =      1.0 : 1.0\n",
      "               sommerset = False             neg : pos    =      1.0 : 1.0\n",
      "                cannibal = False             neg : pos    =      1.0 : 1.0\n",
      "                 reopens = False             neg : pos    =      1.0 : 1.0\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'plot' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-b9319e14c94d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassify\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_set\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow_most_informative_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow_most_informative_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'plot' is not defined"
     ]
    }
   ],
   "source": [
    "classifier = nbc.train(train_set)\n",
    "print nltk.classify.accuracy(classifier, test_set)\n",
    "classifier.show_most_informative_features(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Most Frequent words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u',', 77717), (u'the', 76529), (u'.', 65876), (u'a', 38106), (u'and', 35576), (u'of', 34123), (u'to', 31937), (u\"'\", 30585), (u'is', 25195), (u'in', 21822), (u's', 18513), (u'\"', 17612), (u'it', 16107), (u'that', 15924), (u'-', 15595)]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import random\n",
    "from nltk.corpus import movie_reviews\n",
    "\n",
    "documents = [(list(movie_reviews.words(fileid)), category)\n",
    "             for category in movie_reviews.categories()\n",
    "             for fileid in movie_reviews.fileids(category)]\n",
    "\n",
    "random.shuffle(documents)\n",
    "\n",
    "#print(documents[1])\n",
    "\n",
    "all_words = []\n",
    "for w in movie_reviews.words():\n",
    "    all_words.append(w.lower())\n",
    "\n",
    "all_words = nltk.FreqDist(all_words)\n",
    "print(all_words.most_common(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis â€“ Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk.classify.util\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.corpus import movie_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def word_feats(words):\n",
    "    return dict([(word, True) for word in words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "negids = movie_reviews.fileids('neg')\n",
    "posids = movie_reviews.fileids('pos')\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "negfeats = [(word_feats(movie_reviews.words(fileids=[f])), 'neg') for f in negids]\n",
    "posfeats = [(word_feats(movie_reviews.words(fileids=[f])), 'pos') for f in posids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "negcutoff = len(negfeats)*3/4\n",
    "poscutoff = len(posfeats)*3/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on 1500 instances, test on 500 instances\n"
     ]
    }
   ],
   "source": [
    "trainfeats = negfeats[:negcutoff] + posfeats[:poscutoff]\n",
    "testfeats = negfeats[negcutoff:] + posfeats[poscutoff:]\n",
    "print 'train on %d instances, test on %d instances' % (len(trainfeats), len(testfeats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.728\n",
      "Most Informative Features\n",
      "             magnificent = True              pos : neg    =     15.0 : 1.0\n",
      "             outstanding = True              pos : neg    =     13.6 : 1.0\n",
      "               insulting = True              neg : pos    =     13.0 : 1.0\n",
      "              vulnerable = True              pos : neg    =     12.3 : 1.0\n",
      "               ludicrous = True              neg : pos    =     11.8 : 1.0\n",
      "                  avoids = True              pos : neg    =     11.7 : 1.0\n",
      "             uninvolving = True              neg : pos    =     11.7 : 1.0\n",
      "              astounding = True              pos : neg    =     10.3 : 1.0\n",
      "             fascination = True              pos : neg    =     10.3 : 1.0\n",
      "                 idiotic = True              neg : pos    =      9.8 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier = NaiveBayesClassifier.train(trainfeats)\n",
    "print 'accuracy:', nltk.classify.util.accuracy(classifier, testfeats)\n",
    "classifier.show_most_informative_features()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification for Sentiment Analysis â€“ Stopwords and Collocations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "from nltk.collocations import BigramCollocationFinder\n",
    "from nltk.metrics import BigramAssocMeasures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_classifier(featx):\n",
    "    negids = movie_reviews.fileids('neg')\n",
    "    posids = movie_reviews.fileids('pos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def bigram_word_feats(words, score_fn=BigramAssocMeasures.chi_sq, n=200):\n",
    "    bigram_finder = BigramCollocationFinder.from_words(words)\n",
    "    bigrams = bigram_finder.nbest(score_fn, n)\n",
    "    return dict([(ngram, True) for ngram in itertools.chain(words, bigrams)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "evaluate_classifiers(bigram_word_feats)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
